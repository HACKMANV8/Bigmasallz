# SynthAIx: The Scalable Synthetic Data Generator

[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)
[![Python](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.109+-green.svg)](https://fastapi.tiangolo.com/)
[![Next.js](https://img.shields.io/badge/Next.js-14+-black.svg)](https://nextjs.org/)

SynthAIx is a two-phase, intelligent platform designed to generate large volumes of structured, high-quality synthetic data faster and more reliably than standard LLM chat interfaces.

## 🎯 Key Features

- **Natural Language to Schema**: Convert plain text descriptions into structured JSON schemas
- **Human-in-the-Loop Validation**: Confirm and edit AI-inferred schemas before generation
- **Parallel Processing**: Generate massive datasets using concurrent worker threads
- **Deduplication Engine**: Built-in FastMCP deduplication using ChromaDB vector embeddings
- **Real-time Progress Tracking**: Live status updates and progress monitoring
- **Production-Ready**: Scalable architecture with Docker support

## 🏗️ Architecture

```
┌─────────────────────────────────────────────────────────────┐
│                        Frontend (Next.js)                    │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐      │
│  │ Schema Input │→ │ Confirmation │→ │Progress Track│      │
│  └──────────────┘  └──────────────┘  └──────────────┘      │
└────────────────────────────┬────────────────────────────────┘
                             │ REST API
┌────────────────────────────▼────────────────────────────────┐
│                   Backend (FastAPI Orchestrator)             │
│  ┌──────────────────────────────────────────────────────┐   │
│  │  API Layer                                            │   │
│  │  • /api/schema/translate   • /api/data/generate      │   │
│  │  • /api/jobs/{id}/status                             │   │
│  └────────────────────┬─────────────────────────────────┘   │
│                       │                                      │
│  ┌────────────────────▼─────────────────────────────────┐   │
│  │  Orchestrator Agent                                   │   │
│  │  • Job Management  • Parallel Chunking               │   │
│  └────────────────────┬─────────────────────────────────┘   │
│                       │                                      │
│  ┌────────────────────▼─────────────────────────────────┐   │
│  │  Worker Agents (ThreadPoolExecutor)                   │   │
│  │  ┌──────┐ ┌──────┐ ┌──────┐ ┌──────┐                │   │
│  │  │Agent1│ │Agent2│ │Agent3│ │Agent4│ ... (parallel)  │   │
│  │  └───┬──┘ └───┬──┘ └───┬──┘ └───┬──┘                │   │
│  └──────┼────────┼────────┼────────┼────────────────────┘   │
│         │        │        │        │                         │
│  ┌──────▼────────▼────────▼────────▼─────────────────────┐  │
│  │  FastMCP Deduplication Tool (ChromaDB)                │  │
│  │  • Vector Embeddings  • Similarity Search             │  │
│  └────────────────────────────────────────────────────────┘  │
└─────────────────────────────────────────────────────────────┘
```

## 📁 Project Structure

```
synthaix/
├── backend/                    # FastAPI Backend
│   ├── app/
│   │   ├── api/               # API route handlers
│   │   │   ├── endpoints/     # Individual endpoint modules
│   │   │   │   ├── schema.py  # Schema translation endpoint
│   │   │   │   ├── data.py    # Data generation endpoint
│   │   │   │   └── jobs.py    # Job status endpoint
│   │   │   └── deps.py        # Shared dependencies
│   │   ├── core/              # Core configuration
│   │   │   ├── config.py      # Settings management
│   │   │   └── logging.py     # Logging configuration
│   │   ├── models/            # Pydantic models
│   │   │   ├── schema.py      # Schema models
│   │   │   ├── job.py         # Job models
│   │   │   └── data.py        # Data generation models
│   │   ├── services/          # Business logic
│   │   │   ├── orchestrator.py    # Main orchestrator
│   │   │   ├── schema_service.py  # Schema inference
│   │   │   └── job_service.py     # Job management
│   │   ├── agents/            # Worker agents
│   │   │   ├── generator_agent.py # Data generator worker
│   │   │   └── base_agent.py      # Base agent class
│   │   ├── tools/             # FastMCP tools
│   │   │   ├── deduplication.py   # Deduplication tool
│   │   │   └── vector_store.py    # ChromaDB wrapper
│   │   ├── utils/             # Utility functions
│   │   │   ├── llm_client.py      # LLM API client
│   │   │   └── validators.py      # Data validators
│   │   └── main.py            # FastAPI app entry
│   ├── tests/                 # Backend tests
│   ├── Dockerfile
│   ├── requirements.txt
│   └── pyproject.toml
├── frontend/                   # Next.js Frontend
│   ├── src/
│   │   ├── app/               # Next.js 14 App Router
│   │   │   ├── layout.tsx
│   │   │   ├── page.tsx       # Main page
│   │   │   └── globals.css
│   │   ├── components/        # React components
│   │   │   ├── schema/        # Schema-related components
│   │   │   │   ├── SchemaInput.tsx
│   │   │   │   ├── SchemaEditor.tsx
│   │   │   │   └── SchemaValidator.tsx
│   │   │   ├── generation/    # Generation components
│   │   │   │   ├── GenerationForm.tsx
│   │   │   │   ├── ProgressBar.tsx
│   │   │   │   └── ResultsViewer.tsx
│   │   │   └── ui/            # Shared UI components
│   │   │       ├── Button.tsx
│   │   │       ├── Card.tsx
│   │   │       └── Input.tsx
│   │   ├── services/          # API service layer
│   │   │   ├── api.ts         # API client
│   │   │   ├── schema.ts      # Schema API calls
│   │   │   ├── data.ts        # Data generation API
│   │   │   └── jobs.ts        # Job status API
│   │   ├── hooks/             # Custom React hooks
│   │   │   ├── useSchema.ts
│   │   │   ├── useGeneration.ts
│   │   │   └── useJobStatus.ts
│   │   ├── types/             # TypeScript types
│   │   │   ├── schema.ts
│   │   │   ├── job.ts
│   │   │   └── api.ts
│   │   └── lib/               # Utilities
│   │       └── utils.ts
│   ├── public/
│   ├── tests/
│   ├── Dockerfile
│   ├── package.json
│   ├── tsconfig.json
│   ├── next.config.js
│   └── tailwind.config.ts
├── docker-compose.yml          # Docker orchestration
├── .env.example               # Environment template
├── .gitignore
├── Makefile                   # Development commands
└── README.md
```

## 🚀 Quick Start

### Prerequisites

- Docker & Docker Compose (recommended)
- OR:
  - Python 3.11+
  - Node.js 18+
  - PostgreSQL (optional, for persistent job storage)

### Option 1: Docker (Recommended)

```bash
# Clone the repository
git clone <repository-url>
cd synthaix

# Copy environment template
cp .env.example .env

# Edit .env with your API keys
nano .env

# Start all services
docker-compose up -d

# View logs
docker-compose logs -f
```

Access the application:
- Frontend: http://localhost:3000
- Backend API: http://localhost:8000
- API Documentation: http://localhost:8000/docs

### Option 2: Local Development

#### Backend Setup

```bash
cd backend

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Set environment variables
export OPENAI_API_KEY="your-key-here"
export GOOGLE_API_KEY="your-key-here"  # Optional for Gemini

# Run the server
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

#### Frontend Setup

```bash
cd frontend

# Install dependencies
npm install

# Set environment variables
echo "NEXT_PUBLIC_API_URL=http://localhost:8000" > .env.local

# Run development server
npm run dev
```

## 📚 API Endpoints

### 1. Schema Translation

**POST** `/api/schema/translate`

Converts natural language prompt to structured JSON schema.

**Request Body:**
```json
{
  "prompt": "Generate 10k financial transactions with user ID, amount, currency, and timestamp"
}
```

**Response:**
```json
{
  "schema": {
    "columns": [
      {
        "name": "user_id",
        "type": "string",
        "description": "Unique user identifier"
      },
      {
        "name": "amount",
        "type": "float",
        "description": "Transaction amount"
      },
      {
        "name": "currency",
        "type": "string",
        "description": "Currency code (USD, EUR, etc.)"
      },
      {
        "name": "timestamp",
        "type": "datetime",
        "description": "Transaction timestamp"
      }
    ]
  },
  "inferred_count": 10000
}
```

### 2. Data Generation

**POST** `/api/data/generate`

Initiates parallel synthetic data generation job.

**Request Body:**
```json
{
  "schema": {
    "columns": [...]
  },
  "total_rows": 10000,
  "chunk_size": 500,
  "max_workers": 20,
  "deduplication_threshold": 0.85
}
```

**Response:**
```json
{
  "job_id": "uuid-here",
  "status": "processing",
  "total_rows": 10000,
  "total_chunks": 20,
  "created_at": "2025-10-31T12:00:00Z"
}
```

### 3. Job Status

**GET** `/api/jobs/{job_id}/status`

Retrieves current job progress and results.

**Response:**
```json
{
  "job_id": "uuid-here",
  "status": "processing",
  "total_chunks": 20,
  "completed_chunks": 15,
  "progress_percentage": 75.0,
  "rows_generated": 7500,
  "rows_deduplicated": 250,
  "estimated_completion": "2025-10-31T12:05:00Z",
  "results": null
}
```

When complete:
```json
{
  "job_id": "uuid-here",
  "status": "completed",
  "total_chunks": 20,
  "completed_chunks": 20,
  "progress_percentage": 100.0,
  "rows_generated": 10000,
  "rows_deduplicated": 342,
  "results": {
    "data": [...],
    "download_url": "/api/jobs/uuid-here/download"
  }
}
```

## 🔧 Configuration

### Environment Variables

Create a `.env` file in the root directory:

```env
# LLM Configuration
OPENAI_API_KEY=sk-...
GOOGLE_API_KEY=your-key...
DEFAULT_LLM_PROVIDER=openai
DEFAULT_MODEL=gpt-4-turbo

# Backend Configuration
BACKEND_HOST=0.0.0.0
BACKEND_PORT=8000
LOG_LEVEL=INFO
CORS_ORIGINS=http://localhost:3000

# Generation Settings
MAX_WORKERS=20
DEFAULT_CHUNK_SIZE=500
DEDUPLICATION_THRESHOLD=0.85

# Vector Store (ChromaDB)
CHROMADB_PATH=./data/chromadb
EMBEDDING_MODEL=text-embedding-3-small

# Frontend Configuration
NEXT_PUBLIC_API_URL=http://localhost:8000

# Optional: Database
DATABASE_URL=postgresql://user:pass@localhost:5432/synthaix
```

## 🧪 Testing

### Backend Tests

```bash
cd backend

# Run all tests
pytest

# Run with coverage
pytest --cov=app --cov-report=html

# Run specific test file
pytest tests/test_orchestrator.py -v
```

### Frontend Tests

```bash
cd frontend

# Run unit tests
npm test

# Run E2E tests
npm run test:e2e

# Run with coverage
npm run test:coverage
```

## 📊 Performance & Scalability

### Benchmarks

| Dataset Size | Workers | Time (Standard LLM) | Time (SynthAIx) | Speedup |
|--------------|---------|---------------------|------------------|---------|
| 1,000 rows   | 10      | ~5 min              | ~30 sec          | 10x     |
| 10,000 rows  | 20      | ~50 min             | ~4 min           | 12.5x   |
| 100,000 rows | 50      | ~8 hours            | ~35 min          | 13.7x   |

### Scaling Guidelines

- **Small Jobs** (< 1,000 rows): 5-10 workers, 100-200 chunk size
- **Medium Jobs** (1,000-10,000 rows): 10-20 workers, 500 chunk size
- **Large Jobs** (> 10,000 rows): 20-50 workers, 1,000 chunk size

**Note**: Adjust `max_workers` based on your LLM API rate limits.

## 🛠️ Development

### Makefile Commands

```bash
# Development
make install        # Install all dependencies
make dev            # Start development servers
make format         # Format code (black, prettier)
make lint           # Lint code (ruff, eslint)
make test           # Run all tests

# Docker
make docker-build   # Build Docker images
make docker-up      # Start containers
make docker-down    # Stop containers
make docker-logs    # View logs

# Database
make db-migrate     # Run database migrations
make db-reset       # Reset database
```

## 🎨 Core AI Mechanics

### 1. Parallel Chunking

The Orchestrator uses `concurrent.futures.ThreadPoolExecutor` to split large jobs into parallel chunks:

```python
# 10,000 rows → 20 threads × 500 rows each
with ThreadPoolExecutor(max_workers=20) as executor:
    futures = [
        executor.submit(generate_chunk, schema, 500)
        for _ in range(20)
    ]
```

**Value**: Drastically reduces total generation time through parallel I/O.

### 2. Generator Agents

Each worker thread is a specialized Generator Agent that:
1. Receives a schema and row count
2. Calls the LLM with structured output mode
3. Validates the generated data
4. Applies deduplication
5. Returns results to the orchestrator

**Value**: Encapsulates logic for horizontal scaling.

### 3. FastMCP Deduplication Tool

Uses ChromaDB vector embeddings to ensure data uniqueness:

```python
# Generate embeddings for new rows
embeddings = embedding_model.embed(new_rows)

# Query vector store for similar entries
similar = vector_store.query(embeddings, threshold=0.85)

# Filter out duplicates
unique_rows = [row for row in new_rows if row not in similar]
```

**Value**: Guarantees high-quality, unique records at scale.

## 🔒 Security

- API key management via environment variables
- CORS configuration for production
- Rate limiting on API endpoints
- Input validation and sanitization
- SQL injection protection (if using database)

## 📈 Monitoring & Observability

- Structured logging (JSON format)
- Request/response tracking
- Performance metrics (generation time, throughput)
- Error tracking and alerting
- Health check endpoints

## 🤝 Contributing

1. Fork the repository
2. Create a feature branch: `git checkout -b feature/my-feature`
3. Commit changes: `git commit -am 'Add new feature'`
4. Push to branch: `git push origin feature/my-feature`
5. Submit a pull request

## 📄 License

MIT License - see [LICENSE](LICENSE) file for details.

## 🙏 Acknowledgments

- FastAPI for the excellent async framework
- Next.js for the React framework
- ChromaDB for vector storage
- OpenAI/Google Gemini for LLM APIs

## 📞 Support

- Documentation: [docs/](docs/)
- Issues: [GitHub Issues](https://github.com/yourusername/synthaix/issues)
- Email: support@synthaix.dev

---

**Built with ❤️ by the SynthAIx Team**
